[1mdiff --git a/scripts/state_action_templates.py b/scripts/state_action_templates.py[m
[1mindex 325d9c4..bf993bd 100644[m
[1m--- a/scripts/state_action_templates.py[m
[1m+++ b/scripts/state_action_templates.py[m
[36m@@ -5,8 +5,9 @@[m [mimport numpy as np[m
 [m
 class MDPIsAt:[m
     def __init__(self): [m
[31m-        self.state_name = 'isAt'    # This is the name of the state[m
[31m-        self.action_name = ['Idle', 'moveTo'][m
[32m+[m[32m        self.state_name = 'batteryState'                            # This is the general name the class refers to[m
[32m+[m[32m        self.state_names = ['at_goal', 'not_at_goal']                 # These are the names a certain battery state can have[m
[32m+[m[32m        self.action_names = ['idle', 'move_to']    # These are the names of the actions for internal needs[m
 [m
         self.V = np.array([0, 1])  # Allowable policies, it indicates policies of depth 1[m
         self.B = np.zeros((2, 2, 2))  # Allowable actions initiation[m
[36m@@ -29,21 +30,10 @@[m [mclass MDPIsAt:[m
         # Belief about initial state, D[m
         # -----------------------------------------------------------[m
         self.D = np.array([[0.5], [0.5]])[m
[31m-        # Initial guess about the states d, all equally possible, this is updated over time[m
[31m-        # -----------------------------------------------------------[m
[31m-        self.d = np.array([[0.5], [0.5]])[m
 [m
         # Preference about actions, idle is slightly preferred[m
         # -----------------------------------------------------------[m
         self.E = np.array([[1.01], [1]])[m
         # Learning rate for initial state update[m
         # -----------------------------------------------------------[m
[31m-        self.kappa_d = 0.2[m
[31m-[m
[31m-    # Default habits[m
[31m-    def set_default_preferences(self):[m
[31m-        self.E = np.array([[1.01], [1]])[m
[31m-[m
[31m-    # Default initial estimate[m
[31m-    def reset_belief(self):[m
[31m-        self.d = np.array([[0.5], [0.5]])[m
\ No newline at end of file[m
[32m+[m[32m        self.kappa_d = 0.6[m
